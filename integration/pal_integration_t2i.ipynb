{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8488f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from uuid import uuid4\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "sys.path.append('..')\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from omegaconf import OmegaConf\n",
    "from types import MethodType\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "\n",
    "from src.pal_rm_b_t2i.lightningmodule import LearnerWrapLightning\n",
    "from src.utils import create_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7b389e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt store path: pickapicv2-1-16384-1b9b3397\n",
      "the upper bound is 4\n"
     ]
    }
   ],
   "source": [
    "# init pms (through argparser)\n",
    "conf_learner = '../config/prefLearner_config/t2i-b-dim1024-k1-general-embeddings-mlp2.yaml'\n",
    "conf_ds = '../config/ds_config/pickapicv2_cliph_original_ds.yaml'\n",
    "cache = '../necessary_cache/pickapicv2-dataset-tables'\n",
    "k = 1\n",
    "name = 'pickapicv2'\n",
    "\n",
    "# load configs\n",
    "conf_learner = OmegaConf.load(conf_learner)\n",
    "conf_ds = OmegaConf.load(conf_ds)\n",
    "conf_wandb = OmegaConf.create({'project': 'pal_t2i', 'name': 'pickapicv2', 'save_dir': './logs_wandb/'})\n",
    "user_ids = torch.load(os.path.join(cache,\"user_ids.pt\"))\n",
    "# modify configs\n",
    "conf_learner.preference_learner_params.k = k\n",
    "conf_learner.max_epochs_new_pair = 50\n",
    "conf_ds.batch_size = 16384\n",
    "# init save path\n",
    "random_uuid4 = str(uuid4())[:8]  # This takes only the first 8 characters.\n",
    "filename = create_filename(name, str(k), str(conf_ds.batch_size))\n",
    "filename += f\"-{random_uuid4}\"\n",
    "folder_path = os.path.join(\"./figs\", filename)\n",
    "print(\"ckpt store path:\", filename)\n",
    "\n",
    "learner = LearnerWrapLightning(**conf_learner)\n",
    "learner.preference_learner.user_learner.init_weight(user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5f50ee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\n",
    "    '../ckpts/t2i-ckpts/seen-pickapicv2-cliph-modelB-angle-logistic-k1_trial0-1-16384-ca559ce4-epoch=05.ckpt',\n",
    "    map_location='cpu'\n",
    ")['state_dict']\n",
    "\n",
    "import re\n",
    "# def _tmp_state_dict_converter(state_dict):\n",
    "#     new_state_dict = {}\n",
    "#     for k, v in state_dict.items():\n",
    "#         if 'projector_f.mlp.' in k:\n",
    "#             new_state_dict[k.replace('projector_f.m.', 'projector_f.mlp')] = v\n",
    "#         elif 'item_learner.projector.mlp' in k:\n",
    "#             new_state_dict[k.replace('item_learner.projector.m', 'item_learner.projector.mlp')] = v\n",
    "#         elif re.match(r'user_learner\\.projectors\\.\\d+\\.mlp', k):\n",
    "#             new_state_dict[k.replace('user_learner.projectors.', 'user_learner.projectors.').replace('.m', '.mlp')] = v\n",
    "#         else:\n",
    "#             new_state_dict[k] = v\n",
    "#     return new_state_dict\n",
    "\n",
    "def _tmp_state_dict_converter(state_dict):\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if '.m.' in k:\n",
    "            new_state_dict[k.replace('.m.', '.mlp.')] = v\n",
    "        else:\n",
    "            new_state_dict[k] = v\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a08442ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learner.load_state_dict(state_dict)\n",
    "learner.load_state_dict(_tmp_state_dict_converter(state_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cd39d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_mix_forward_b(pal: torch.nn.Module, mix_weight: torch.tensor):\n",
    "    # override the forward function of the pal to be a standard reward model\n",
    "    # after the modification, the pal will be able to output:\n",
    "    # model a: the reward diff given a prompt\n",
    "    # model b: the reward logits given a prompt\n",
    "    def mix_forward_userlearner(self, latent_prompts):\n",
    "        prompt_logits = self.infer_gk(latent_prompts)   # (bs, k, dims)\n",
    "        bs = prompt_logits.size(0)\n",
    "        w = self.softmax(mix_weight.repeat(bs, 1))  # (bs, k)\n",
    "        w = w.unsqueeze(1)  # (bs, 1, k)\n",
    "        y_hat = torch.bmm(w, prompt_logits) # (bs, 1, dims)\n",
    "        y_hat = y_hat.squeeze(1)    # (bs, dims)\n",
    "        self.tmp_store_user_ideal_points = y_hat\n",
    "        return y_hat\n",
    "    def mix_forward_itemlearner(self, items):\n",
    "        x = self.connector_x(items)\n",
    "        if self.learner_type in ['dist','dist_normalization','angle','dist_logistic','angle_hinge']:  # |f(x)-f(u)|_2 or <f(x), f(u)>\n",
    "            return self.projector(x)\n",
    "        elif self.learner_type == 'norm':   # # |f(x-u)|_2 (do the self.projector() part in the PreferenceLearner)\n",
    "            return x\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown learner_type={self.learner_type}.\")\n",
    "    def mix_map_preflearner(self, x):\n",
    "        # ({\n",
    "        # 'input_ids': prompt_input_ids,\\\n",
    "        # 'attention_mask': prompt_attention_mask,\n",
    "        # },\\\n",
    "        # {\n",
    "        # 'input_ids': eval_input_ids,\\\n",
    "        # 'attention_mask': eval_attention_mask,\\\n",
    "        # })\n",
    "        prompt, items = x\n",
    "        items_prime = self.item_learner(items)\n",
    "        prompt_prime = self.user_learner(prompt)\n",
    "        return items_prime, prompt_prime\n",
    "    def mix_forward_preflearner(self, x):\n",
    "        items, prompt = x\n",
    "        items_prime, prompt_prime = self.map_to_pref_embedding_space((prompt, items))\n",
    "        print(f\"{items_prime[0]=}\")\n",
    "        print(f\"{prompt_prime[0]=}\")\n",
    "        print(f\"{items_prime.shape=}\")\n",
    "        print(f\"{prompt_prime.shape=}\")\n",
    "        if self.pref_learner_type == 'angle':\n",
    "            items_prime = items_prime / torch.norm(items_prime, dim=-1, keepdim=True)\n",
    "            prompt_prime = prompt_prime / torch.norm(prompt_prime, dim=-1, keepdim=True)\n",
    "            prompt_prime = prompt_prime.unsqueeze(1)\n",
    "            logit_scale = self.logit_scale.exp()\n",
    "            clamped_logit_scale = torch.clamp(logit_scale, max=100)\n",
    "            # print(clamped_logit_scale)\n",
    "            # print((prompt_prime * items_prime).sum(dim=-1))\n",
    "            sim_score = (prompt_prime * items_prime).sum(dim=-1) * clamped_logit_scale   # (bs, max_token_length)\n",
    "            return sim_score\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    def forwad(self, batch):\n",
    "        y_hat = self.preference_learner(batch)\n",
    "        return y_hat\n",
    "    pal.preference_learner.user_learner.forward = MethodType(mix_forward_userlearner, pal.preference_learner.user_learner)\n",
    "    pal.preference_learner.item_learner.forward = MethodType(mix_forward_itemlearner, pal.preference_learner.item_learner)\n",
    "    pal.preference_learner.map_to_pref_embedding_space = MethodType(mix_map_preflearner, pal.preference_learner)\n",
    "    pal.preference_learner.forward = MethodType(mix_forward_preflearner, pal.preference_learner)\n",
    "    pal.forward = MethodType(forwad, pal)\n",
    "    return pal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3841bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pal = wrap_mix_forward_b(learner, torch.tensor([0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a8327652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_prime[0]=tensor([-0.8441,  0.8796,  0.6785,  ...,  1.2911,  1.8600,  1.2384],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "prompt_prime[0]=tensor([ 1.5011, -1.0693, -1.5910,  ..., -1.7996,  0.4741, -1.2623],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "items_prime.shape=torch.Size([1, 1024])\n",
      "prompt_prime.shape=torch.Size([1, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8308]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_prompt_latent = torch.randn(1, 1024)\n",
    "tmp_item_latent = torch.randn(1, 1024)\n",
    "pal([tmp_prompt_latent, tmp_item_latent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9351dbdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f32f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f909c425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f98646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95523f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b7895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f81c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc28dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
